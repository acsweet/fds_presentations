{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os, gc, json, re\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeplerGL\n",
    "- https://kepler.gl/\n",
    "- jupyter user guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_income_data(path, file_name):\n",
    "    df_income = pd.read_csv(path + file_name)\n",
    "\n",
    "    cols = ['GEO_ID', 'NAME']\n",
    "    update_col_names = {}\n",
    "    lower_level = [] # for calculating a weighted average\n",
    "    for col_name, col_data in df_income.head(1).iteritems():\n",
    "        real_name = col_data.values[0]\n",
    "        if 'Estimate' in real_name:\n",
    "            income_level = re.findall(r'\\d+(?:,\\d+)?', real_name)\n",
    "            if len(income_level) == 1:\n",
    "                if 'less than' in real_name.lower():\n",
    "                    new_name = 'less than ' + income_level[0]\n",
    "                    lower_num = 0\n",
    "                elif 'more' in real_name.lower():\n",
    "                    new_name = income_level[0] + ' or more'\n",
    "                    lower_num = int(income_level[0].replace(',', ''))\n",
    "            if len(income_level) == 2:\n",
    "                new_name = income_level[0] + ' to ' + income_level[1]\n",
    "                lower_num = int(income_level[0].replace(',', ''))\n",
    "\n",
    "            if len(income_level) > 0:\n",
    "                lower_level.append(lower_num)\n",
    "                update_col_names.update({col_name: new_name})\n",
    "                cols.append(col_name)\n",
    "\n",
    "    df_income_clean = df_income[cols].rename(update_col_names, axis = 1).drop(0).reset_index(drop = True)\n",
    "    income_level_cols = [c for c in list(df_income_clean) if c not in ['GEO_ID', 'NAME']]\n",
    "    row_totals = df_income_clean[income_level_cols].astype(int).sum(axis = 1)\n",
    "    weighted_sums = df_income_clean[income_level_cols].astype(int).values * np.array(lower_level)\n",
    "    weighted_avgs = weighted_sums.sum(axis = 1) / row_totals\n",
    "    df_income_clean['weighted_avg_income'] = weighted_avgs\n",
    "    df_income_clean['GEO_ID'] = df_income_clean['GEO_ID'].str.replace('1500000US', '')\n",
    "    # clean the weighted_avg_income column for display\n",
    "    df_income_clean['Weighted Average Income'] = df_income_clean['weighted_avg_income'].apply('${:,.2f}'.format)\n",
    "    \n",
    "    return df_income_clean\n",
    "\n",
    "def get_census_income():\n",
    "    income_files = {\n",
    "        '2018': 'ACSDT5Y2018.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "        '2017': 'ACSDT5Y2017.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "        '2016': 'ACSDT5Y2016.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "        '2015': 'ACSDT5Y2015.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "        '2014': 'ACSDT5Y2014.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "        '2013': 'ACSDT5Y2015.B19001_data_with_overlays_2020-02-13T163519.csv',\n",
    "    }\n",
    "\n",
    "    path = './data/Census Bureau/Income/productDownload_2020-02-13T163538/'\n",
    "    df_final = pd.DataFrame()\n",
    "    for year, file_name in income_files.items():\n",
    "        df_current = clean_income_data(path, file_name)\n",
    "        df_current['Year'] = pd.to_datetime(str(year), format = '%Y')\n",
    "        df_final = df_final.append(df_current, sort = False).reset_index(drop = True)\n",
    "        \n",
    "    df_final = df_final.rename({'GEO_ID': 'GEOID'}, axis = 1)\n",
    "    df_final = df_final.sort_values(by = ['Year'], ascending = False).reset_index(drop = True)\n",
    "    return df_final\n",
    "\n",
    "def get_spatial_df_from_clusters(df, min_cluster_observations = 10, crs = 'EPSG:4326'):\n",
    "    xy_clusters = df[['x', 'y', 'clusters']].groupby('clusters').agg(['mean', 'std', 'count']).reset_index()\n",
    "    xy_clusters.columns = [(e[0] + ' ' + e[1]).strip() for e in list(xy_clusters)]\n",
    "    xy_clusters = xy_clusters.loc[xy_clusters['x count'] >= 24].reset_index(drop = True)\n",
    "    geometry = gpd.points_from_xy(xy_clusters['x mean'], xy_clusters['y mean'])\n",
    "    gdf_clusters = gpd.GeoDataFrame(xy_clusters, geometry = geometry)\n",
    "    gdf_clusters.crs = crs\n",
    "    \n",
    "    gdf_clusters = gdf_clusters.rename({'y count': 'count'}, axis = 1)\n",
    "    gdf_clusters = gdf_clusters.drop(['x std', 'y std', 'x count'], axis = 1)\n",
    "    return gdf_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks\n",
    "- data: https://www.kaggle.com/starbucks/store-locations/version/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/Starbucks/'\n",
    "df = pd.read_csv(path + 'directory.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = gpd.points_from_xy(df['Longitude'], df['Latitude'])\n",
    "gdf_starbucks = gpd.GeoDataFrame(df, geometry = geometries)\n",
    "gdf_starbucks.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height = 500, data = {'starbucks': gdf_starbucks})\n",
    "map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census\n",
    "\n",
    "### Income Data\n",
    "- data: https://data.census.gov/cedsci/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following function cleans and formats the original csv downloads\n",
    "df_income = get_census_income()\n",
    "df_income.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will plot the distribution of average income in the data\n",
    "df_income['weighted_avg_income'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Tract Map\n",
    "- shapefile: https://catalog.data.gov/dataset/tiger-line-shapefile-2017-state-california-current-block-group-state-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_path = './data/Census Tracts and Block Groups/tl_2017_06_bg/'\n",
    "shape_file = 'tl_2017_06_bg.shp'\n",
    "gdf = gpd.GeoDataFrame.from_file(shape_path + shape_file)\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['GEOID', 'geometry']\n",
    "\n",
    "# change the crs and filter to Fresno County\n",
    "gdf = gdf.to_crs(epsg = '4326')\n",
    "gdf_fresno = gdf[cols].loc[gdf['COUNTYFP'] == '019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height = 500, data = {'fresno_census_tracts': gdf_fresno})\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_cols = ['GEOID', 'weighted_avg_income', 'Weighted Average Income', 'Year']\n",
    "gdf_merged_income = gdf_fresno.merge(df_income[income_cols], on = 'GEOID')\n",
    "gdf_merged_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height = 500, data = {'fresno_income': gdf_merged_income})\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbx_cols = ['Store Number', 'Store Name', 'City', 'geometry']\n",
    "local_starbucks = gdf_starbucks[sbx_cols].loc[gdf_starbucks['City'].isin(['Fresno', 'Clovis'])]\n",
    "local_starbucks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Join\n",
    "- with geopandas.sjoin()\n",
    "    - https://geopandas.org/reference/geopandas.sjoin.html\n",
    "- be sure the coordinate systems are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbx_and_income = gpd.sjoin(local_starbucks, gdf_merged_income)\n",
    "sbx_and_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbx_and_income.loc[sbx_and_income['Year'].dt.year == 2018].groupby(['City']).agg({'weighted_avg_income': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Store Name', 'City', 'weighted_avg_income', 'Weighted Average Income', 'Year', 'geometry']\n",
    "map_1 = KeplerGl(height = 500, \n",
    "                 data = {'fresno_income': sbx_and_income.loc[sbx_and_income['Year'].dt.year == 2018, cols]})\n",
    "map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Power of Geospatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/location_shapefile/Location_Tracking.shp'\n",
    "gdf = gpd.GeoDataFrame.from_file(file)\n",
    "gdf = gdf.to_crs(epsg = '4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gdf.geometry.x\n",
    "y = gdf.geometry.y\n",
    "xy_data = pd.DataFrame({'x': x, 'y': y})\n",
    "xy_data = xy_data.reset_index()\n",
    "xy_data.plot(x = 'x', y= 'y', kind = 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering down the data\n",
    "- First we will find the minimum distance of each point to any other point\n",
    "- Then we will filter all points to be within one standard deviation of the mean of those minimum distances\n",
    "- This essentially tries to filter points to existing clusters or groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_data_cartesian = xy_data.copy()\n",
    "xy_data_cartesian['key'] = 1\n",
    "xy_data_cartesian = xy_data_cartesian.merge(xy_data_cartesian, on = 'key', suffixes = ('_1', '_2'))\n",
    "xy_data_cartesian = xy_data_cartesian.loc[xy_data_cartesian['index_1'] != xy_data_cartesian['index_2']].reset_index(drop = True)\n",
    "xy_data_cartesian['distance'] = np.sqrt(((xy_data_cartesian[['x_1', 'y_1']].values - xy_data_cartesian[['x_2', 'y_2']].values)**2).sum(axis = 1))\n",
    "\n",
    "xy_data_min_d = xy_data_cartesian.groupby('index_1').agg({'distance': 'min'}).reset_index()\n",
    "mean_min_d = xy_data_min_d['distance'].mean()\n",
    "std_min_d = xy_data_min_d['distance'].std()\n",
    "\n",
    "xy_data_filtered = xy_data.merge(xy_data_min_d, left_on = 'index', right_on = 'index_1').drop(['index', 'index_1'], axis = 1)\n",
    "xy_data_filtered = xy_data_filtered.loc[np.abs(xy_data_filtered['distance'] - mean_min_d) <= 1*std_min_d]\n",
    "\n",
    "xy_data_filtered.plot(x = 'x', y= 'y', kind = 'scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "- https://scikit-learn.org/stable/modules/clustering.html\n",
    "- the clustering algorithm will attempt to give each group a distinct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters = 4, random_state = 0)\n",
    "clusters = model.fit_predict(xy_data_filtered[['x', 'y']])\n",
    "xy_data_filtered['clusters'] = clusters\n",
    "xy_data_filtered.plot.scatter(x = 'x', y = 'y', c = 'clusters', colormap = 'plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_clusters = get_spatial_df_from_clusters(xy_data_filtered, min_cluster_observations = 24)\n",
    "gdf_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height = 500, data = {'location_points': gdf_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file = './data/Fresno County/Parcels/Fresno_Parcels.shp'\n",
    "gdf_parcels = gpd.read_file(shp_file)\n",
    "gdf_parcels_fresno = gdf_parcels.loc[gdf_parcels['AGENCY_COD'] == 'FR']\n",
    "gdf_parcels_fresno = gdf_parcels_fresno.to_crs(epsg=4326)\n",
    "\n",
    "# refresh map above and check the layers\n",
    "# when adding data to a map, it might not be displayed on the map\n",
    "# in that case it will have to be done from within the map\n",
    "map_1.add_data(data = gdf_parcels_fresno, name = 'fresno_parcels')\n",
    "\n",
    "# this will load a map config file if you have one\n",
    "# after changing the map to your liking, you can save map.config into a json file to load later\n",
    "# with open('fresno_parcel_and_location_map_config.json', 'r') as f:\n",
    "#     map_config = json.load(f)\n",
    "# map_1.config = map_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
